{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Math prerequisites\n",
    "### LECTURE: Entropy and cross-entropy\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2TD8IyfBGXiY"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yo63BJPf0cau"
   },
   "source": [
    "# Reminder of entropy:\n",
    "\n",
    "$$H(p) = -\\sum_x p(x)\\log(p(x))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vmjUxlEqGbDu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong entropy: 0.34657359027997264\n"
     ]
    }
   ],
   "source": [
    "# probability of an event happening\n",
    "p = .25\n",
    "\n",
    "# NOT the correct formula!\n",
    "H = -( p*np.log(p) )\n",
    "print('Wrong entropy: ' + str(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if P = 0.25 is the probability of the event happening\n",
    "# then the probability of the event not hapenning is 1-P = 0.75\n",
    "# minimum for a distribution where the event happens or not should contain atlease 2 probability\n",
    "# so x = [p, 1-p] in case of a 2 state system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HdZadwd12RGv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct entropy: 0.5623351446188083\n"
     ]
    }
   ],
   "source": [
    "# the correct way to compute entropy\n",
    "x = [.25,.75]\n",
    "\n",
    "H = 0\n",
    "for p in x:\n",
    "  H -= p*np.log(p) # or H += -p*np.log(p)\n",
    "\n",
    "print('Correct entropy: ' + str(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R_bGT7kd2ipR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct entropy: 0.5623351446188083\n"
     ]
    }
   ],
   "source": [
    "# also correct, written out for N=2 events\n",
    "\n",
    "# Binary cross-entropy\n",
    "H = -( p*np.log(p) + (1-p)*np.log(1-p) )\n",
    "print('Correct entropy: ' + str(H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFN5779d1ebD"
   },
   "source": [
    "# Cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sOug_tPzHY1y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy: 1.3862943611198906\n"
     ]
    }
   ],
   "source": [
    "# note: all probs must sum to 1! # attained using the softmax function\n",
    "p = [   1,0   ] # sum=1\n",
    "q = [ .25,.75 ] # sum=1\n",
    "\n",
    "H = 0\n",
    "for i in range(len(p)):\n",
    "  H -= p[i]*np.log(q[i])\n",
    "\n",
    "print('Cross entropy: ' + str(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8H1p7JUr3Pn4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct entropy: 1.3862943611198906\n",
      "Manually simplified: 1.3862943611198906\n"
     ]
    }
   ],
   "source": [
    "# also correct, written out for N=2 events\n",
    "H = -( p[0]*np.log(q[0]) + p[1]*np.log(q[1]) )\n",
    "print('Correct entropy: ' + str(H))\n",
    "\n",
    "# simplification\n",
    "H = -np.log(q[0])\n",
    "print('Manually simplified: ' + str(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fAHoba2V4QgO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3863)\n"
     ]
    }
   ],
   "source": [
    "# now using pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# note: inputs must be Tensors\n",
    "q_tensor = torch.Tensor(q)\n",
    "p_tensor = torch.Tensor(p)\n",
    "\n",
    "ce=F.binary_cross_entropy(q_tensor,p_tensor) # swapped in tensor\n",
    "# first input is the model output\n",
    "# second input is the training data\n",
    "print(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1692941200690,
     "user": {
      "displayName": "Mike X Cohen",
      "userId": "13901636194183843661"
     },
     "user_tz": -180
    },
    "id": "QBQabnEEJisd",
    "outputId": "c0f67256-1c5e-4929-86b8-ec36f2db4f1d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1oDaogKfz9gQYSAyQT-uF9xRI3EdrtokO",
     "timestamp": 1618209287295
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
